"""
Web Vulnerability Scanner Module - Nikto Integration and HTTP Analysis
"""

import json
import requests
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple
from pathlib import Path
from urllib.parse import urlparse, urljoin

from src.core import ScannerBase, ScanResult, ScanStatus, ScanSeverity
from src.core import CommandExecutor, validate_url, validate_domain, validate_ip
from src.utils.logger import log_info, log_error, log_warning


class WebScanner(ScannerBase):
    """
    Web vulnerability scanner using Nikto and custom HTTP analysis
    """

    def __init__(self, timeout: int = 180):
        """
        Initialize web scanner

        Args:
            timeout: Scan timeout in seconds
        """
        super().__init__("web_scanner", timeout=timeout)
        self.executor = CommandExecutor(timeout=self.timeout)

        # HTTP session for requests
        self.session = requests.Session()
        self.session.timeout = 30

        # Default User-Agent
        self.session.headers.update(
            {"User-Agent": "Auto-Pentest-Tool/1.0 (Security Scanner)"}
        )

        # Security headers to check
        self.security_headers = {
            "Strict-Transport-Security": "HSTS",
            "Content-Security-Policy": "CSP",
            "X-Frame-Options": "X-Frame-Options",
            "X-Content-Type-Options": "X-Content-Type-Options",
            "X-XSS-Protection": "X-XSS-Protection",
            "Referrer-Policy": "Referrer-Policy",
            "Permissions-Policy": "Permissions-Policy",
        }

        # Common web technologies signatures
        self.tech_signatures = {
            "server": ["Apache", "nginx", "IIS", "LiteSpeed"],
            "cms": ["WordPress", "Joomla", "Drupal", "Magento"],
            "frameworks": ["Laravel", "Django", "Rails", "Express"],
        }

    def validate_target(self, target: str) -> bool:
        """
        Validate if target is appropriate for web scanning

        Args:
            target: Target URL, domain, or IP

        Returns:
            bool: True if valid target, False otherwise
        """
        # Accept URLs directly
        if target.startswith(("http://", "https://")):
            return validate_url(target)

        # Accept domains and IPs (will be converted to URLs)
        return validate_domain(target) or validate_ip(target)

    def _execute_scan(self, target: str, options: Dict[str, Any]) -> ScanResult:
        """
        Execute web vulnerability scan

        Args:
            target: Target to scan
            options: Scan options

        Returns:
            ScanResult: Parsed scan results
        """
        result = ScanResult(
            scanner_name=self.name,
            target=target,
            status=ScanStatus.RUNNING,
            start_time=datetime.now(),
        )

        try:
            # Normalize target to URL
            target_url = self._normalize_target_url(target, options)
            result.target = target_url

            self.logger.info(f"Starting web scan on: {target_url}")

            # Phase 1: HTTP Header Analysis
            self._analyze_http_headers(target_url, result)

            # Phase 2: Technology Detection
            self._detect_technologies(target_url, result)

            # Phase 3: Security Headers Check
            self._check_security_headers(target_url, result)

            # Phase 4: Robots.txt Analysis
            self._analyze_robots_txt(target_url, result)

            # Phase 5: Nikto Scan (if available)
            if options.get("use_nikto", True):
                self._run_nikto_scan(target_url, result)

            # Phase 6: HTTP Methods Testing
            self._test_http_methods(target_url, result)

            result.status = ScanStatus.COMPLETED
            self.logger.info(
                f"Web scan completed. Found {len(result.findings)} findings"
            )

        except Exception as e:
            result.status = ScanStatus.FAILED
            result.errors.append(f"Web scan failed: {str(e)}")
            self.logger.error(f"Web scan error: {e}")

        return result

    def _normalize_target_url(self, target: str, options: Dict[str, Any]) -> str:
        """
        Normalize target to proper URL format

        Args:
            target: Target string
            options: Scan options

        Returns:
            str: Normalized URL
        """
        # If already a complete URL, validate and return
        if target.startswith(("http://", "https://")):
            try:
                from urllib.parse import urlparse

                parsed = urlparse(target)
                if parsed.hostname:
                    return target
                else:
                    raise ValueError("Invalid URL format")
            except Exception:
                raise ValueError(f"Invalid URL: {target}")

        # Build URL from components
        scheme = options.get("scheme", "https")
        port = options.get("port")

        # Validate scheme
        if scheme not in ["http", "https"]:
            raise ValueError(f"Invalid scheme: {scheme}")

        # Handle port
        if port:
            if not isinstance(port, int) or port < 1 or port > 65535:
                raise ValueError(f"Invalid port: {port}")
            return f"{scheme}://{target}:{port}"
        else:
            return f"{scheme}://{target}"

    def _analyze_http_headers(self, url: str, result: ScanResult) -> None:
        """
        Analyze HTTP response headers

        Args:
            url: Target URL
            result: ScanResult to populate
        """
        try:
            # Send HEAD request first (faster)
            response = self.session.head(url, allow_redirects=True, timeout=30)

            # If HEAD fails, try GET
            if response.status_code == 405:  # Method Not Allowed
                response = self.session.get(url, allow_redirects=True, timeout=30)

            # Store basic response info
            result.metadata["http_status"] = response.status_code
            result.metadata["final_url"] = response.url
            result.metadata["redirect_count"] = len(response.history)

            # Analyze response headers
            headers = response.headers

            # Server information
            server = headers.get("Server", "")
            if server:
                result.add_finding(
                    title=f"Server Information: {server}",
                    description=f"Server header reveals: {server}",
                    severity=ScanSeverity.INFO,
                    category="server_info",
                    server=server,
                    details={"header": "Server", "value": server},
                )

            # Technology detection from headers
            self._detect_tech_from_headers(headers, result)

            # Check for verbose headers (information disclosure)
            self._check_verbose_headers(headers, result)

            # Powered-By headers
            powered_by = headers.get("X-Powered-By", "")
            if powered_by:
                result.add_finding(
                    title=f"Technology Disclosure: {powered_by}",
                    description=f"X-Powered-By header reveals: {powered_by}",
                    severity=ScanSeverity.LOW,
                    category="tech_disclosure",
                    technology=powered_by,
                    details={"header": "X-Powered-By", "value": powered_by},
                )

        except requests.exceptions.RequestException as e:
            result.errors.append(f"HTTP request failed: {str(e)}")
            self.logger.error(f"HTTP request error: {e}")
        except Exception as e:
            result.errors.append(f"Header analysis failed: {str(e)}")
            self.logger.error(f"Header analysis error: {e}")

    def _detect_tech_from_headers(self, headers: dict, result: ScanResult) -> None:
        """
        Detect technologies from HTTP headers

        Args:
            headers: HTTP response headers
            result: ScanResult to populate
        """
        tech_headers = {
            "X-AspNet-Version": "ASP.NET",
            "X-AspNetMvc-Version": "ASP.NET MVC",
            "X-Powered-By": "Various",
            "X-Generator": "CMS/Framework",
            "X-Drupal-Cache": "Drupal",
            "X-Pingback": "WordPress",
        }

        for header, tech in tech_headers.items():
            value = headers.get(header)
            if value:
                result.add_finding(
                    title=f"Technology Detected: {tech}",
                    description=f"Detected {tech} from {header} header: {value}",
                    severity=ScanSeverity.INFO,
                    category="technology_detection",
                    technology=tech,
                    header=header,
                    value=value,
                )

    def _check_verbose_headers(self, headers: dict, result: ScanResult) -> None:
        """
        Check for verbose/debug headers that may leak information

        Args:
            headers: HTTP response headers
            result: ScanResult to populate
        """
        verbose_headers = [
            "X-Debug",
            "X-Debug-Info",
            "X-Error-Detail",
            "X-Runtime",
            "X-Request-ID",
            "X-Correlation-ID",
            "X-Varnish",
            "X-Cache",
            "X-Cache-Status",
        ]

        for header in verbose_headers:
            value = headers.get(header)
            if value:
                severity = (
                    ScanSeverity.MEDIUM
                    if "debug" in header.lower()
                    else ScanSeverity.LOW
                )

                result.add_finding(
                    title=f"Verbose Header: {header}",
                    description=f"Header {header} may leak information: {value}",
                    severity=severity,
                    category="info_disclosure",
                    header=header,
                    value=value,
                )

    def _detect_technologies(self, url: str, result: ScanResult) -> None:
        """
        Detect web technologies in use

        Args:
            url: Target URL
            result: ScanResult to populate
        """
        try:
            # Get full page content for analysis
            response = self.session.get(url, timeout=30)
            content = response.text.lower()
            headers = response.headers

            # CMS Detection
            self._detect_cms(content, headers, result)

            # Framework Detection
            self._detect_frameworks(content, headers, result)

            # JavaScript Libraries
            self._detect_js_libraries(content, result)

            # Web Server Detection (from headers and content)
            self._detect_web_server(headers, content, result)

        except requests.exceptions.RequestException as e:
            result.errors.append(f"Technology detection request failed: {str(e)}")
            self.logger.error(f"Technology detection error: {e}")
        except Exception as e:
            result.errors.append(f"Technology detection failed: {str(e)}")
            self.logger.error(f"Technology detection error: {e}")

    def _detect_cms(self, content: str, headers: dict, result: ScanResult) -> None:
        """Detect Content Management Systems"""
        cms_signatures = {
            "WordPress": [
                "wp-content/",
                "wp-includes/",
                "wp-admin/",
                "wordpress",
                "/wp-json/",
                "wp-embed.min.js",
            ],
            "Joomla": [
                "/joomla/",
                "joomla!",
                "option=com_",
                "/administrator/",
                "joomla.framework",
            ],
            "Drupal": [
                "drupal",
                "/sites/default/",
                "/modules/",
                "drupal.js",
                "x-drupal-cache",
            ],
        }

        for cms, signatures in cms_signatures.items():
            matches = [sig for sig in signatures if sig in content]
            if matches:
                result.add_finding(
                    title=f"CMS Detected: {cms}",
                    description=f"Detected {cms} CMS based on signatures: {', '.join(matches[:3])}",
                    severity=ScanSeverity.INFO,
                    category="cms_detection",
                    technology=cms,
                    signatures=matches[:5],  # Limit to 5 matches
                )

    def _detect_frameworks(
        self, content: str, headers: dict, result: ScanResult
    ) -> None:
        """Detect Web Frameworks"""
        framework_signatures = {
            "Laravel": ["laravel_session", "laravel", "/laravel/"],
            "Django": ["django", "csrfmiddlewaretoken", "/django/"],
            "Rails": ["rails", "ruby on rails", "_session_id"],
            "Express": ["express", "x-powered-by: express"],
            "Spring": ["spring", "jsessionid", "/spring/"],
            "Flask": ["flask", "/flask/"],
        }

        for framework, signatures in framework_signatures.items():
            matches = [sig for sig in signatures if sig in content]
            if matches:
                result.add_finding(
                    title=f"Framework Detected: {framework}",
                    description=f"Detected {framework} framework",
                    severity=ScanSeverity.INFO,
                    category="framework_detection",
                    technology=framework,
                    signatures=matches,
                )

    def _detect_js_libraries(self, content: str, result: ScanResult) -> None:
        """Detect JavaScript Libraries"""
        js_libraries = {
            "jQuery": ["jquery", "/jquery.js", "/jquery.min.js"],
            "Bootstrap": ["bootstrap", "/bootstrap.js", "/bootstrap.min.js"],
            "Angular": ["angular", "ng-app", "ng-controller"],
            "React": ["react", "reactjs", "_react"],
            "Vue.js": ["vue.js", "vue.min.js", "v-if", "v-for"],
        }

        for library, signatures in js_libraries.items():
            matches = [sig for sig in signatures if sig in content]
            if matches:
                result.add_finding(
                    title=f"JavaScript Library: {library}",
                    description=f"Detected {library} JavaScript library",
                    severity=ScanSeverity.INFO,
                    category="js_library",
                    technology=library,
                    signatures=matches,
                )

    def _detect_web_server(
        self, headers: dict, content: str, result: ScanResult
    ) -> None:
        """Detect Web Server from headers and content"""
        server = headers.get("Server", "").lower()

        # Common servers
        servers = {
            "apache": "Apache HTTP Server",
            "nginx": "Nginx",
            "iis": "Microsoft IIS",
            "litespeed": "LiteSpeed",
            "cloudflare": "Cloudflare",
        }

        for server_name, full_name in servers.items():
            if server_name in server:
                result.add_finding(
                    title=f"Web Server: {full_name}",
                    description=f"Detected {full_name} web server",
                    severity=ScanSeverity.INFO,
                    category="web_server",
                    technology=full_name,
                    server_header=server,
                )

    def _check_security_headers(self, url: str, result: ScanResult) -> None:
        """
        Check for security-related HTTP headers

        Args:
            url: Target URL
            result: ScanResult to populate
        """
        try:
            response = self.session.get(url, timeout=30)
            headers = response.headers

            # Check each security header
            for header, description in self.security_headers.items():
                value = headers.get(header)

                if value:
                    # Header is present - analyze value
                    severity = self._analyze_security_header(header, value)

                    result.add_finding(
                        title=f"Security Header Present: {description}",
                        description=f"{description} header is configured: {value}",
                        severity=severity,
                        category="security_header_present",
                        header=header,
                        value=value,
                        recommendation="Verify header configuration is appropriate",
                    )
                else:
                    # Header is missing
                    severity = self._get_missing_header_severity(header)

                    result.add_finding(
                        title=f"Missing Security Header: {description}",
                        description=f"{description} header is not set",
                        severity=severity,
                        category="security_header_missing",
                        header=header,
                        recommendation=self._get_header_recommendation(header),
                    )

            # Check for insecure headers
            self._check_insecure_headers(headers, result)

        except requests.exceptions.RequestException as e:
            result.errors.append(f"Security headers check failed: {str(e)}")
            self.logger.error(f"Security headers check error: {e}")

    def _analyze_security_header(self, header: str, value: str) -> ScanSeverity:
        """Analyze security header value for issues"""
        value_lower = value.lower()

        if header == "Strict-Transport-Security":
            if "max-age" not in value_lower or "max-age=0" in value_lower:
                return ScanSeverity.MEDIUM
            return ScanSeverity.INFO

        elif header == "Content-Security-Policy":
            if "unsafe-inline" in value_lower or "unsafe-eval" in value_lower:
                return ScanSeverity.MEDIUM
            return ScanSeverity.INFO

        elif header == "X-Frame-Options":
            if value_lower in ["deny", "sameorigin"]:
                return ScanSeverity.INFO
            return ScanSeverity.MEDIUM

        return ScanSeverity.INFO

    def _get_missing_header_severity(self, header: str) -> ScanSeverity:
        """Get severity for missing security headers"""
        critical_headers = ["Strict-Transport-Security", "Content-Security-Policy"]
        important_headers = ["X-Frame-Options", "X-Content-Type-Options"]

        if header in critical_headers:
            return ScanSeverity.MEDIUM
        elif header in important_headers:
            return ScanSeverity.LOW
        else:
            return ScanSeverity.INFO

    def _get_header_recommendation(self, header: str) -> str:
        """Get recommendation for missing header"""
        recommendations = {
            "Strict-Transport-Security": "Add HSTS header: Strict-Transport-Security: max-age=31536000; includeSubDomains",
            "Content-Security-Policy": "Implement CSP to prevent XSS attacks",
            "X-Frame-Options": "Add X-Frame-Options: DENY or SAMEORIGIN to prevent clickjacking",
            "X-Content-Type-Options": "Add X-Content-Type-Options: nosniff",
            "X-XSS-Protection": "Add X-XSS-Protection: 1; mode=block",
            "Referrer-Policy": "Add Referrer-Policy: strict-origin-when-cross-origin",
            "Permissions-Policy": "Consider adding Permissions-Policy for feature control",
        }
        return recommendations.get(header, f"Consider adding {header} security header")

    def _check_insecure_headers(self, headers: dict, result: ScanResult) -> None:
        """Check for insecure header configurations"""
        # Check for server version disclosure
        server = headers.get("Server", "")
        if any(
            version_indicator in server.lower() for version_indicator in ["/", "(", "v"]
        ):
            result.add_finding(
                title="Server Version Disclosure",
                description=f"Server header reveals version information: {server}",
                severity=ScanSeverity.LOW,
                category="info_disclosure",
                header="Server",
                value=server,
                recommendation="Configure server to hide version information",
            )

    def _analyze_robots_txt(self, url: str, result: ScanResult) -> None:
        """
        Analyze robots.txt file

        Args:
            url: Target URL
            result: ScanResult to populate
        """
        try:
            # Build robots.txt URL
            from urllib.parse import urljoin

            robots_url = urljoin(url, "/robots.txt")

            response = self.session.get(robots_url, timeout=15)

            if response.status_code == 200:
                robots_content = response.text
                result.metadata["robots_txt_found"] = True

                # Parse robots.txt content
                self._parse_robots_content(robots_content, robots_url, result)

            elif response.status_code == 404:
                result.add_finding(
                    title="No robots.txt File",
                    description="robots.txt file not found",
                    severity=ScanSeverity.INFO,
                    category="robots_txt",
                    status="not_found",
                    recommendation="Consider adding robots.txt file",
                )
            else:
                result.add_finding(
                    title=f"robots.txt Access Issue",
                    description=f"robots.txt returned status code: {response.status_code}",
                    severity=ScanSeverity.LOW,
                    category="robots_txt",
                    status_code=response.status_code,
                )

        except requests.exceptions.RequestException as e:
            result.errors.append(f"robots.txt analysis failed: {str(e)}")
            self.logger.debug(f"robots.txt analysis error: {e}")

    def _parse_robots_content(
        self, content: str, robots_url: str, result: ScanResult
    ) -> None:
        """Parse robots.txt content for interesting findings"""
        lines = content.strip().split("\n")
        disallowed_paths = []
        interesting_paths = []
        sitemaps = []

        for line in lines:
            line = line.strip()
            if line.startswith("Disallow:"):
                path = line.split(":", 1)[1].strip()
                if path and path != "/":
                    disallowed_paths.append(path)

                    # Check for interesting paths
                    if any(
                        keyword in path.lower()
                        for keyword in [
                            "admin",
                            "backup",
                            "private",
                            "config",
                            "test",
                            "dev",
                            "staging",
                        ]
                    ):
                        interesting_paths.append(path)

            elif line.startswith("Sitemap:"):
                sitemap = line.split(":", 1)[1].strip()
                sitemaps.append(sitemap)

        # Report findings
        if disallowed_paths:
            result.add_finding(
                title="robots.txt Disallowed Paths",
                description=f"Found {len(disallowed_paths)} disallowed paths in robots.txt",
                severity=ScanSeverity.INFO,
                category="robots_txt",
                robots_url=robots_url,
                disallowed_count=len(disallowed_paths),
                paths=disallowed_paths[:10],  # First 10 paths
                details={"all_paths": disallowed_paths},
            )

        if interesting_paths:
            result.add_finding(
                title="Interesting Paths in robots.txt",
                description=f"Found potentially interesting paths: {', '.join(interesting_paths[:5])}",
                severity=ScanSeverity.MEDIUM,
                category="robots_txt",
                interesting_paths=interesting_paths,
                recommendation="Review these paths for sensitive information",
            )

        if sitemaps:
            result.add_finding(
                title="Sitemaps Found in robots.txt",
                description=f"Found {len(sitemaps)} sitemap(s) in robots.txt",
                severity=ScanSeverity.INFO,
                category="robots_txt",
                sitemaps=sitemaps,
            )

    def _run_nikto_scan(self, url: str, result: ScanResult) -> None:
        """
        Run Nikto vulnerability scan

        Args:
            url: Target URL
            result: ScanResult to populate
        """
        # TODO: Implement Nikto integration
        # - Check if nikto is available
        # - Build nikto command
        # - Execute scan
        # - Parse output
        # - Convert to findings

        self.logger.debug("Nikto scan - TODO")
        pass

    def _test_http_methods(self, url: str, result: ScanResult) -> None:
        """
        Test allowed HTTP methods

        Args:
            url: Target URL
            result: ScanResult to populate
        """
        try:
            # Test OPTIONS method first
            options_response = self.session.options(url, timeout=15)

            allowed_methods = []
            dangerous_methods = []

            # Check Allow header
            allow_header = options_response.headers.get("Allow", "")
            if allow_header:
                allowed_methods = [method.strip() for method in allow_header.split(",")]

                # Check for dangerous methods
                dangerous = ["PUT", "DELETE", "PATCH", "TRACE", "CONNECT"]
                dangerous_methods = [
                    method for method in allowed_methods if method in dangerous
                ]

                if dangerous_methods:
                    result.add_finding(
                        title="Dangerous HTTP Methods Allowed",
                        description=f"Potentially dangerous HTTP methods are allowed: {', '.join(dangerous_methods)}",
                        severity=ScanSeverity.HIGH,
                        category="http_methods",
                        dangerous_methods=dangerous_methods,
                        all_methods=allowed_methods,
                        recommendation="Disable unnecessary HTTP methods on the server",
                    )

                result.add_finding(
                    title="HTTP Methods Information",
                    description=f"Allowed HTTP methods: {', '.join(allowed_methods)}",
                    severity=ScanSeverity.INFO,
                    category="http_methods",
                    allowed_methods=allowed_methods,
                )

            # Test individual methods
            methods_to_test = ["GET", "POST", "PUT", "DELETE", "HEAD", "TRACE"]
            method_results = {}

            for method in methods_to_test:
                try:
                    test_response = self.session.request(method, url, timeout=10)
                    method_results[method] = test_response.status_code

                    # Special check for TRACE method
                    if method == "TRACE" and test_response.status_code == 200:
                        result.add_finding(
                            title="TRACE Method Enabled",
                            description="TRACE method is enabled, which may allow XST attacks",
                            severity=ScanSeverity.MEDIUM,
                            category="http_methods",
                            method="TRACE",
                            recommendation="Disable TRACE method to prevent XST attacks",
                        )

                except requests.exceptions.RequestException:
                    method_results[method] = "Failed"

            result.metadata["http_methods_tested"] = method_results

        except requests.exceptions.RequestException as e:
            result.errors.append(f"HTTP methods testing failed: {str(e)}")
            self.logger.debug(f"HTTP methods testing error: {e}")
        except Exception as e:
            result.errors.append(f"HTTP methods testing error: {str(e)}")
            self.logger.error(f"HTTP methods testing error: {e}")

    def _parse_nikto_output(self, nikto_output: str, result: ScanResult) -> None:
        """
        Parse Nikto scan output

        Args:
            nikto_output: Raw nikto output
            result: ScanResult to populate
        """
        # TODO: Implement Nikto output parsing
        # - Parse CSV or XML output
        # - Extract vulnerabilities
        # - Map to severity levels
        # - Create findings

        self.logger.debug("Nikto output parsing - TODO")
        pass

    def _determine_web_severity(
        self, finding_type: str, details: Dict[str, Any]
    ) -> ScanSeverity:
        """
        Determine severity level for web findings

        Args:
            finding_type: Type of finding
            details: Finding details

        Returns:
            ScanSeverity: Severity level
        """
        # Critical security issues
        if finding_type in ["sql_injection", "command_injection", "code_execution"]:
            return ScanSeverity.CRITICAL

        # High severity vulnerabilities
        if finding_type in [
            "xss",
            "file_inclusion",
            "directory_traversal",
            "authentication_bypass",
        ]:
            return ScanSeverity.HIGH

        # Medium severity issues
        if finding_type in [
            "info_disclosure",
            "missing_security_headers",
            "weak_authentication",
        ]:
            return ScanSeverity.MEDIUM

        # Low severity findings
        if finding_type in [
            "technology_detection",
            "version_disclosure",
            "verbose_headers",
        ]:
            return ScanSeverity.LOW

        # Informational findings
        if finding_type in ["robots_txt", "server_info", "http_methods"]:
            return ScanSeverity.INFO

        # Check specific header-related issues
        if finding_type == "security_header_missing":
            header = details.get("header", "")
            critical_headers = ["Strict-Transport-Security", "Content-Security-Policy"]
            if header in critical_headers:
                return ScanSeverity.MEDIUM
            return ScanSeverity.LOW

        # Default based on category patterns
        if "vulnerability" in finding_type or "exploit" in finding_type:
            return ScanSeverity.HIGH
        elif "security" in finding_type or "weak" in finding_type:
            return ScanSeverity.MEDIUM
        elif "missing" in finding_type or "disclosure" in finding_type:
            return ScanSeverity.LOW

        return ScanSeverity.INFO

    def get_capabilities(self) -> Dict[str, Any]:
        """
        Get scanner capabilities

        Returns:
            Dict: Scanner capabilities and information
        """
        # Check for required tools
        nikto_available = self.executor.check_tool_exists("nikto")
        nikto_version = (
            self.executor.get_tool_version("nikto") if nikto_available else None
        )

        return {
            "name": self.name,
            "description": "Web vulnerability scanner and HTTP analysis",
            "version": "1.0.0",
            "supported_targets": ["url", "domain", "ip"],
            "scan_types": [
                "http_headers",
                "security_headers",
                "technology_detection",
                "nikto_scan",
                "robots_analysis",
                "http_methods",
            ],
            "timeout": self.timeout,
            "dependencies": {
                "requests": "Python requests library",
                "nikto": {
                    "required": False,
                    "version": nikto_version,
                    "available": nikto_available,
                },
            },
            "options": {
                "scheme": "URL scheme (http/https)",
                "port": "Custom port number",
                "use_nikto": "Enable Nikto scanning",
                "user_agent": "Custom User-Agent string",
                "follow_redirects": "Follow HTTP redirects",
            },
            "features": [
                "HTTP header analysis",
                "Security headers checking",
                "Web technology detection",
                "Nikto vulnerability scanning",
                "Robots.txt analysis",
                "HTTP methods testing",
                "Information disclosure detection",
            ],
        }

    def quick_web_scan(self, target: str) -> ScanResult:
        """
        Perform a quick web scan (headers and basic checks only)

        Args:
            target: Target URL, domain, or IP

        Returns:
            ScanResult: Scan results
        """
        options = {"use_nikto": False, "scheme": "https"}
        return self.scan(target, options)

    def full_web_scan(self, target: str) -> ScanResult:
        """
        Perform a comprehensive web scan (all checks including Nikto)

        Args:
            target: Target URL, domain, or IP

        Returns:
            ScanResult: Scan results
        """
        options = {"use_nikto": True, "scheme": "https", "follow_redirects": True}
        return self.scan(target, options)
